{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consumes:\n",
    "\n",
    "- An eval split from ExampleGen\n",
    "- A trained model from Trainer\n",
    "- A previously blessed model (if validation to be performed)\n",
    "\n",
    "Emits:\n",
    "\n",
    "- Analysis results to ML Metadata\n",
    "- Validation results to ML Metadata (if validation to be performed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To setup the evaluator the following information is needed:\n",
    "\n",
    "- Metrics to configure (only reqired if additional metrics are being added outside of those saved with the model). See [Tensorflow Model Analysis Metrics](https://github.com/tensorflow/model-analysis/blob/master/g3doc/metrics.md) for more information.\n",
    "- Slices to configure (if not slices are given then an \"overall\" slice will be added by default). See [Tensorflow Model Analysis Setup](https://github.com/tensorflow/model-analysis/blob/master/g3doc/setup.md) for more information.\n",
    "\n",
    "If validation is to be included, the following additional information is needed:\n",
    "\n",
    "- Which model to compare against (latest blessed, etc).\n",
    "- Model validations (thresholds) to verify. See [Tensorflow Model Analysis Model Validations](https://github.com/tensorflow/model-analysis/blob/master/g3doc/model_validations.md) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx import components\n",
    "import tensorflow_model_analysis as tfma\n",
    "\n",
    "...\n",
    "\n",
    "# For TFMA evaluation\n",
    "\n",
    "eval_config = tfma.EvalConfig(\n",
    "    model_specs=[\n",
    "        # This assumes a serving model with signature 'serving_default'. If\n",
    "        # using estimator based EvalSavedModel, add signature_name='eval' and\n",
    "        # remove the label_key. Note, if using a TFLite model, then you must set\n",
    "        # model_type='tf_lite'.\n",
    "        tfma.ModelSpec(label_key='<label_key>')\n",
    "    ],\n",
    "    metrics_specs=[\n",
    "        tfma.MetricsSpec(\n",
    "            # The metrics added here are in addition to those saved with the\n",
    "            # model (assuming either a keras model or EvalSavedModel is used).\n",
    "            # Any metrics added into the saved model (for example using\n",
    "            # model.compile(..., metrics=[...]), etc) will be computed\n",
    "            # automatically.\n",
    "            metrics=[\n",
    "                tfma.MetricConfig(class_name='ExampleCount')\n",
    "            ],\n",
    "            # To add validation thresholds for metrics saved with the model,\n",
    "            # add them keyed by metric name to the thresholds map.\n",
    "            thresholds = {\n",
    "                \"binary_accuracy\": tfma.MetricThreshold(\n",
    "                    value_threshold=tfma.GenericValueThreshold(\n",
    "                        lower_bound={'value': 0.5}),\n",
    "                    change_threshold=tfma.GenericChangeThreshold(\n",
    "                       direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
    "                       absolute={'value': -1e-10}))\n",
    "            }\n",
    "        )\n",
    "    ],\n",
    "    slicing_specs=[\n",
    "        # An empty slice spec means the overall slice, i.e. the whole dataset.\n",
    "        tfma.SlicingSpec(),\n",
    "        # Data can be sliced along a feature column. In this case, data is\n",
    "        # sliced along feature column trip_start_hour.\n",
    "        tfma.SlicingSpec(feature_keys=['trip_start_hour'])\n",
    "    ])\n",
    "\n",
    "# The following component is experimental and may change in the future. This is\n",
    "# required to specify the latest blessed model will be used as the baseline.\n",
    "model_resolver = ResolverNode(\n",
    "      instance_name='latest_blessed_model_resolver',\n",
    "      resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n",
    "      model=Channel(type=Model),\n",
    "      model_blessing=Channel(type=ModelBlessing))\n",
    "\n",
    "model_analyzer = components.Evaluator(\n",
    "      examples=examples_gen.outputs['examples'],\n",
    "      model=trainer.outputs['model'],\n",
    "      baseline_model=model_resolver.outputs['model'],\n",
    "      # Change threshold will be ignored if there is no baseline (first run).\n",
    "      eval_config=eval_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
