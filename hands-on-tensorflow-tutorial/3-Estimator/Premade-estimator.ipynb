{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\n",
      "8192/2194 [================================================================================================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\n",
      "8192/573 [============================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "_map = {\n",
    "    0: 'Setosa',\n",
    "    1: 'Versicolor',\n",
    "    2: 'Virginica',\n",
    "}\n",
    "train_y = train_y.map(_map)\n",
    "test_y = test_y.map(_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of programming with Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To write a TensorFlow program based on pre-made Estimators, you must perform the following tasks:\n",
    "\n",
    "- Create one or more input functions.\n",
    "- Define the model's feature columns.\n",
    "- Instantiate an Estimator, specifying the feature columns and various hyperparameters.\n",
    "- Call one or more methods on the Estimator object, passing the appropriate input function as the source of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create input functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An __input function__ is a function that returns a `tf.data.Dataset` object which outputs the following two-element tuple:\n",
    "\n",
    "- `features` - A Python dictionary in which:\n",
    "    - Each key is the name of a feature.\n",
    "    - Each value is an array containing all of that feature's values.\n",
    "- `label` - An array containing the values of the label for every example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features: pd.DataFrame, labels, training=True, batch_size=256):\n",
    "    \"\"\"An input function for training or evaluating\"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((features.to_dict(orient='list'), labels))\n",
    "    \n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "        \n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the feature columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A feature column is an object describing how the model should use raw input data from the features dictionary. When you build an Estimator model, you pass it a list of feature columns that describes each of the features you want the model to use. The `tf.feature_column` module provides many options for representing data to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "for key in train.keys():\n",
    "    feature_columns.append(tf.feature_column.numeric_column(key=key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate an estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some premade classifier estimators:\n",
    "- tf.estimator.DNNClassifier: for deep models that perform multi-class classification.\n",
    "- tf.estimator.DNNLinearCombinedClassifier: for wide & deep models.\n",
    "- tf.estimator.LinearClassifier: for classifiers based on linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmptn4pk9dt\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmptn4pk9dt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.DNNClassifier(\n",
    "    hidden_units=[30, 10],\n",
    "    feature_columns=feature_columns,\n",
    "    n_classes=3,\n",
    "    label_vocabulary=['Setosa', 'Versicolor', 'Virginica']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Evaluate, and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmptn4pk9dt/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 2.7911055, step = 0\n",
      "INFO:tensorflow:global_step/sec: 339.461\n",
      "INFO:tensorflow:loss = 1.4232947, step = 100 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.526\n",
      "INFO:tensorflow:loss = 1.1717352, step = 200 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.599\n",
      "INFO:tensorflow:loss = 1.056201, step = 300 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 409.973\n",
      "INFO:tensorflow:loss = 0.9975603, step = 400 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.965\n",
      "INFO:tensorflow:loss = 0.9520955, step = 500 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.985\n",
      "INFO:tensorflow:loss = 0.9271631, step = 600 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.937\n",
      "INFO:tensorflow:loss = 0.9034118, step = 700 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.242\n",
      "INFO:tensorflow:loss = 0.88097614, step = 800 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.027\n",
      "INFO:tensorflow:loss = 0.8623118, step = 900 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.628\n",
      "INFO:tensorflow:loss = 0.8466301, step = 1000 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.995\n",
      "INFO:tensorflow:loss = 0.82773757, step = 1100 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.528\n",
      "INFO:tensorflow:loss = 0.80945617, step = 1200 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.519\n",
      "INFO:tensorflow:loss = 0.8045274, step = 1300 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.703\n",
      "INFO:tensorflow:loss = 0.77613914, step = 1400 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.997\n",
      "INFO:tensorflow:loss = 0.76845115, step = 1500 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.723\n",
      "INFO:tensorflow:loss = 0.7503612, step = 1600 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.216\n",
      "INFO:tensorflow:loss = 0.7315221, step = 1700 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.864\n",
      "INFO:tensorflow:loss = 0.73132795, step = 1800 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.773\n",
      "INFO:tensorflow:loss = 0.7016095, step = 1900 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.824\n",
      "INFO:tensorflow:loss = 0.6933331, step = 2000 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.045\n",
      "INFO:tensorflow:loss = 0.6955845, step = 2100 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.01\n",
      "INFO:tensorflow:loss = 0.68911767, step = 2200 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.169\n",
      "INFO:tensorflow:loss = 0.67249984, step = 2300 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.861\n",
      "INFO:tensorflow:loss = 0.6704762, step = 2400 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.423\n",
      "INFO:tensorflow:loss = 0.6431085, step = 2500 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.77\n",
      "INFO:tensorflow:loss = 0.64320195, step = 2600 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.445\n",
      "INFO:tensorflow:loss = 0.6353122, step = 2700 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.22\n",
      "INFO:tensorflow:loss = 0.6338715, step = 2800 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.749\n",
      "INFO:tensorflow:loss = 0.63338536, step = 2900 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.242\n",
      "INFO:tensorflow:loss = 0.61068547, step = 3000 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.31\n",
      "INFO:tensorflow:loss = 0.621097, step = 3100 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.106\n",
      "INFO:tensorflow:loss = 0.60505855, step = 3200 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 409.631\n",
      "INFO:tensorflow:loss = 0.5939411, step = 3300 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.142\n",
      "INFO:tensorflow:loss = 0.593568, step = 3400 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.929\n",
      "INFO:tensorflow:loss = 0.5820527, step = 3500 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.201\n",
      "INFO:tensorflow:loss = 0.5747274, step = 3600 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.461\n",
      "INFO:tensorflow:loss = 0.57365566, step = 3700 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.684\n",
      "INFO:tensorflow:loss = 0.5439915, step = 3800 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.608\n",
      "INFO:tensorflow:loss = 0.564907, step = 3900 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.13\n",
      "INFO:tensorflow:loss = 0.54531044, step = 4000 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.82\n",
      "INFO:tensorflow:loss = 0.5510783, step = 4100 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.271\n",
      "INFO:tensorflow:loss = 0.5445973, step = 4200 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.714\n",
      "INFO:tensorflow:loss = 0.52969885, step = 4300 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.926\n",
      "INFO:tensorflow:loss = 0.5320564, step = 4400 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.971\n",
      "INFO:tensorflow:loss = 0.5229201, step = 4500 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.459\n",
      "INFO:tensorflow:loss = 0.5135559, step = 4600 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.87\n",
      "INFO:tensorflow:loss = 0.5310084, step = 4700 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.733\n",
      "INFO:tensorflow:loss = 0.5165795, step = 4800 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.509\n",
      "INFO:tensorflow:loss = 0.54111564, step = 4900 (0.241 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmptn4pk9dt/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.51315236.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7fac4ab82790>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "    hooks=None,\n",
    "    steps=5000,\n",
    "    max_steps=None,\n",
    "    saving_listeners=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `average_loss` (mean loss per sample)\n",
    "- the `loss` (mean loss per mini-batch)\n",
    "- estimator's `global_step` (the number of training iterations it underwent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-19T04:59:03Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptn4pk9dt/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.22765s\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-19-04:59:03\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.53333336, average_loss = 0.6261574, global_step = 5000, loss = 0.6261574\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmptn4pk9dt/model.ckpt-5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.53333336,\n",
       " 'average_loss': 0.6261574,\n",
       " 'loss': 0.6261574,\n",
       " 'global_step': 5000}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results = classifier.evaluate(input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions from the model\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predict_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "}\n",
    "\n",
    "def input_fn(features, batch_size=256):\n",
    "    \"\"\"An input function for prediction.\"\"\"\n",
    "    # Convert the inputs to a Dataset without labels.\n",
    "    return tf.data.Dataset.from_tensor_slices(features).batch(batch_size)\n",
    "\n",
    "predictions = classifier.predict(input_fn=lambda: input_fn(predict_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptn4pk9dt/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is \"Setosa\" (72.9%), expected \"Setosa\"\n",
      "Prediction is \"Virginica\" (42.9%), expected \"Versicolor\"\n",
      "Prediction is \"Virginica\" (69.9%), expected \"Virginica\"\n"
     ]
    }
   ],
   "source": [
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    pred_class = pred_dict['classes'][0]\n",
    "    probability = pred_dict['probabilities'][pred_dict['class_ids'][0]]\n",
    "    \n",
    "    print('Prediction is \"{}\" ({:.1f}%), expected \"{}\"'.format(pred_class.decode('UTF-8'), 100*probability, expec))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
