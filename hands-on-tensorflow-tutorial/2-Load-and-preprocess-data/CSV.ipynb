{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\"\n",
    "TEST_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/eval.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filepath = tf.keras.utils.get_file('train.csv', TRAIN_DATA_URL)\n",
    "test_filepath = tf.keras.utils.get_file('test.csv', TEST_DATA_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(filepath, **kwargs):\n",
    "    return tf.data.experimental.make_csv_dataset(\n",
    "        file_pattern=filepath,\n",
    "        batch_size=32,\n",
    "        label_name='survived',\n",
    "        na_value='?', # Additional string to recognize as NA/NaN\n",
    "        num_epochs=1, # used for repeat the dataset, leave it as 1 then specify epochs in model.fit\n",
    "        ignore_errors=True,\n",
    "        **kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_dataset = get_dataset(train_filepath)\n",
    "raw_test_dataset = get_dataset(test_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Illustrate other parameters in make_csv_dataset:\n",
    "\n",
    "# Specify column names\n",
    "CSV_COLUMNS = ['survived', 'sex', 'age', 'n_siblings_spouses', 'parch', 'fare', 'class', 'deck', 'embark_town', 'alone']\n",
    "temp_dataset = get_dataset(train_filepath, column_names=CSV_COLUMNS)\n",
    "\n",
    "# Specify selected columns\n",
    "SELECT_COLUMNS = ['survived', 'age', 'n_siblings_spouses', 'parch', 'fare']\n",
    "DEFAULTS = [0, 0.0, 0.0, 0.0, 0.0]\n",
    "temp_dataset = get_dataset(train_filepath, select_columns=SELECT_COLUMNS, column_defaults=DEFAULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Csv dataset use dict to store features, like:\n",
    "# <\n",
    "# PrefetchDataset shapes:\n",
    "#     (OrderedDict([\n",
    "#         (age, (None,)), \n",
    "#         (n_siblings_spouses, (None,)), \n",
    "#         (parch, (None,)), \n",
    "#         (fare, (None,))\n",
    "#     ]),\n",
    "#      (None,)),\n",
    "# types:\n",
    "#     (OrderedDict([\n",
    "#         (age, tf.float32), \n",
    "#         (n_siblings_spouses, tf.float32), \n",
    "#         (parch, tf.float32), \n",
    "#         (fare, tf.float32)]), \n",
    "#      tf.int32)\n",
    "# >\n",
    "# So we need to pack features together for each sample\n",
    "def pack(features, label):\n",
    "    return tf.stack(list(features.values()), axis=-1), label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continous data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have mixed datatypes you may want to separate out these simple-numeric fields. The `tf.feature_column` api can handle them, but this incurs some overhead and should be avoided unless really necessary.\n",
    "\n",
    "So define a more general preprocessor that selects a list of numeric features and packs them into a single column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PackNumericFeatures:\n",
    "    def __init__(self, names):\n",
    "        self.names = names\n",
    "    def __call__(self, features, labels):\n",
    "        # NOTE: the features is a orderDict\n",
    "        # Also, the features and labels are already batched\n",
    "        numeric_features = [features.pop(name) for name in self.names]\n",
    "        numeric_features = [tf.cast(feat, tf.float32) for feat in numeric_features]\n",
    "        numeric_features = tf.stack(numeric_features, axis=-1)\n",
    "        features['numeric'] = numeric_features\n",
    "        \n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIC_FEATURES = ['age','n_siblings_spouses','parch', 'fare']\n",
    "\n",
    "packed_train_data = raw_train_dataset.map(PackNumericFeatures(NUMERIC_FEATURES))\n",
    "packed_test_data = raw_test_dataset.map(PackNumericFeatures(NUMERIC_FEATURES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data Normalization__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "desc = pd.read_csv(train_filepath)[NUMERIC_FEATURES].describe()\n",
    "MEAN = desc.T['mean'].values\n",
    "STD = desc.T['std'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_numeric_data(mean, std):\n",
    "    def _normalize_numeric_data(data):\n",
    "        return (data - mean) / std\n",
    "    return _normalize_numeric_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_column = tf.feature_column.numeric_column(\n",
    "    key='numeric', # A unique string identifying the input feature.\n",
    "    shape=(len(NUMERIC_FEATURES),),\n",
    "    normalizer_fn=normalize_numeric_data(MEAN, STD)\n",
    ")\n",
    "numeric_columns = [numeric_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cause the original dataset's features are OrdierDict\n",
    "# so we first use feature_column to fetch the values by `key`\n",
    "# then, we use DenseFeature layer to convert to Dense Tensor\n",
    "# (DenseFeature will concatenate all the Dense Tensor)\n",
    "numeric_layer = tf.keras.layers.DenseFeatures(numeric_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `tf.feature_column` API to create a collection with a `tf.feature_column.indicator_column` for each categorical column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = {\n",
    "    'sex': ['male', 'female'],\n",
    "    'class' : ['First', 'Second', 'Third'],\n",
    "    'deck' : ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'],\n",
    "    'embark_town' : ['Cherbourg', 'Southhampton', 'Queenstown'],\n",
    "    'alone' : ['y', 'n']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = []\n",
    "for feature_name, vocab in CATEGORIES.items():\n",
    "    cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        key=feature_name,\n",
    "        vocabulary_list=vocab\n",
    "    )\n",
    "    categorical_columns.append(tf.feature_column.indicator_column(cat_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_layer = tf.keras.layers.DenseFeatures(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 20 means all the above one-hot encoding concatenate together\n",
    "# The 32 is just batch size\n",
    "categorical_layer(example_batch).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined preprocessing layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_layer = tf.keras.layers.DenseFeatures(categorical_columns + numeric_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    preprocessing_layer,\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, evaluate, and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = packed_train_data.shuffle(500)\n",
    "test_data = packed_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4267: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4322: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.5899 - accuracy: 0.6316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f95901a3750>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alone': <tf.Tensor 'alone:0' shape=(None, 1) dtype=string>,\n",
       " 'class': <tf.Tensor 'class:0' shape=(None, 1) dtype=string>,\n",
       " 'deck': <tf.Tensor 'deck:0' shape=(None, 1) dtype=string>,\n",
       " 'embark_town': <tf.Tensor 'embark_town:0' shape=(None, 1) dtype=string>,\n",
       " 'numeric': <tf.Tensor 'numeric:0' shape=(None, 4) dtype=float32>,\n",
       " 'sex': <tf.Tensor 'sex:0' shape=(None, 1) dtype=string>}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inputs\n",
    "# The numeric features normalization and categorical features preprocessing\n",
    "# are done in preprocessing layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
