{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = int(2e4)\n",
    "MAX_LENGTH = 40 # Use the max_length to filter out examples with more than 40 tokens for faster training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True, as_supervised=True)\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SubwordTextEncoder encodes the string by breaking it into subwords if the word is not in its dictionary. The whitespace ` ` will be used `_` to represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (en.numpy() for pt, en in train_examples),\n",
    "    target_vocab_size=2**13)\n",
    "tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (pt.numpy() for pt, en in train_examples),\n",
    "    target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [7915, 1248, 7946, 7194, 13, 2799, 7877]\n",
      "The original string: Transformer is awesome.\n",
      "7915 ----> T\n",
      "1248 ----> ran\n",
      "7946 ----> s\n",
      "7194 ----> former \n",
      "13 ----> is \n",
      "2799 ----> awesome\n",
      "7877 ----> .\n"
     ]
    }
   ],
   "source": [
    "sample_string = 'Transformer is awesome.'\n",
    "\n",
    "tokenized_string = tokenizer_en.encode(sample_string)\n",
    "print ('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "original_string = tokenizer_en.decode(tokenized_string)\n",
    "print ('The original string: {}'.format(original_string))\n",
    "\n",
    "assert original_string == sample_string\n",
    "\n",
    "for ts in tokenized_string:\n",
    "    print ('{} ----> {}'.format(ts, tokenizer_en.decode([ts])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add start and end token to the input and target. Here we use `vocab_size` to represents start token, `vocab_size + 1` to represents end token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(pt, en):\n",
    "    pt = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(pt.numpy()) + [tokenizer_pt.vocab_size+1]\n",
    "    en = [tokenizer_en.vocab_size] + tokenizer_en.encode(en.numpy()) + [tokenizer_en.vocab_size+1]\n",
    "    return pt, en\n",
    "\n",
    "# Warp the `encode` function to that it could be added to graph.\n",
    "def tf_encode(pt, en):\n",
    "    _pt, _en = tf.py_function(encode, inp=(pt, en), Tout=(tf.int64, tf.int64))\n",
    "    _pt.set_shape = [None]\n",
    "    _en.set_shape = [None]\n",
    "    return _pt, _en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.size(tf.zeros((3, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
    "    # tf.size returns the number of all elements in tensor.\n",
    "    # e.g. shape of [3, 5] --> 15\n",
    "    return tf.logical_and(tf.size(x) <= max_length, tf.size(y) <= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_examples.map(tf_encode) # string -> int64\n",
    "train_dataset = train_dataset.filter(filter_max_length) # filters out examples with > 40 tokens\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE, padded_shapes=([None], [None]))\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "val_dataset = val_examples.map(tf_encode)\n",
    "val_dataset = val_dataset.filter(filter_max_length)\n",
    "val_dataset = val_dataset.padded_batch(BATCH_SIZE, padded_shapes=([None], [None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 38]), TensorShape([64, 40]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_batch, en_batch = next(iter(train_dataset))\n",
    "pt_batch.shape, en_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angle(pos, i, d_model):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        pos: word position.\n",
    "        i: embedding_position.\n",
    "        d_model: size of embedding.\n",
    "    \"\"\"\n",
    "    # position-0: 10000**(0/d_model)\n",
    "    # position-1: 10000**(0/d_model)\n",
    "    # position-2: 10000**(2/d_model)\n",
    "    # position-3: 10000**(2/d_model)\n",
    "    # ...\n",
    "    angle_rates = 1 / np.power(10000, (2*(i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(sequence_length, d_model):\n",
    "    angle_rads = get_angle(\n",
    "        pos=np.arange(sequence_length)[:, np.newaxis], # [len_pos, 1]\n",
    "        i=np.arange(d_model)[np.newaxis, :], # [1, d_model]\n",
    "        d_model=d_model)\n",
    "    \n",
    "    # Apply sin to even indices in the array: 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    # Apply cos to odd indices in the array: 2i+2\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...] # [1, len_pos, d_model]\n",
    "    \n",
    "    return tf.cast(pos_encoding, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 30, 128)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(sequence_length=30, d_model=128)\n",
    "print(pos_encoding.shape)\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 128))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask all pad tokens in the batch of sequence. It ensures that the model does not treat padding as the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(sequence):\n",
    "    mask = tf.cast(tf.math.equal(sequence, 0), tf.float32)\n",
    "    # Add extra dimensions to add the padding to the attention logits.\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :] # [BATCH_SIZE, 1, 1, seq_len] ([BATCH_SIZE, NUM_HEADS, seq_len_q, seq_len_k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[1., 0., 0., 1., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[7, 6, 0, 0, 1], [0, 6, 8, 0, 1]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask ahead words, which means that to predict the third word, only the first and second word will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(seq_len):\n",
    "    # tf.linalg.band_part num_lower=-1 --> Lower triangular part.\n",
    "    # tf.linalg.band_part num_upper=0 --> Diagonal.\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), num_lower=-1, num_upper=0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_look_ahead_mask(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled dot product attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.tensorflow.org/images/tutorials/transformer/scaled_attention.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask=None):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "    q, k, v must have matching leading dimensions.\n",
    "    k, v must have matchin penultimate dimension, i.e.: seq_len_k = seq_len_v\n",
    "    The mask has different shapes depending on its type(padding or look ahead)\n",
    "    but it must be broadcastable for addition.\n",
    "    \n",
    "    Args:\n",
    "        q: query shape == (..., seq_len_q, depth)\n",
    "        k: key shape == (..., seq_len_k, depth)\n",
    "        v: value shape == (..., seq_len_v, depth_v)\n",
    "        mask: Float tensor with shape broadcastable to (..., seq_len_q, seq_len_k). Defaults to None\n",
    "    \n",
    "    Returns:\n",
    "        output, attention_weights\n",
    "    \"\"\"\n",
    "    \n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True) # (..., seq_len_q, seq_len_k)\n",
    "    \n",
    "    # scale matmul_qk\n",
    "    depth_k = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(depth_k) # (..., seq_len_q, seq_len_k)\n",
    "    \n",
    "    # Add the mask to the scaled attention logits.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "        \n",
    "        \n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1) # (..., seq_len_q, seq_len_k)\n",
    "    \n",
    "    context = tf.matmul(attention_weights, v) # (..., seq_len_q, depth_v)\n",
    "    \n",
    "    return context, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def print_out(q, k, v):\n",
    "    temp_out, temp_attn = scaled_dot_product_attention(q, k, v, None)\n",
    "    print ('Attention weights are:')\n",
    "    print (temp_attn)\n",
    "    print ('Output is:')\n",
    "    print (temp_out)\n",
    "\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "\n",
    "# This `query` aligns with the second `key`, so the second `value` is returned.\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns with a repeated key (third and fourth), \n",
    "# so all associated values get averaged.\n",
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns equally with the first and second key, \n",
    "# so their values get averaged.\n",
    "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# All together\n",
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-head attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](https://www.tensorflow.org/images/tutorials/transformer/multi_head_attention.png)\n",
    "\n",
    "Contains:\n",
    "- Linear layers and split into heads.\n",
    "- Scaled dot-product attention.\n",
    "- Concatenation of heads.\n",
    "- Final linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        assert d_model % self.num_heads == 0\n",
    "        \n",
    "        # depth for each head\n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.Wq = tf.keras.layers.Dense(d_model)\n",
    "        self.Wk = tf.keras.layers.Dense(d_model)\n",
    "        self.Wv = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the late dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \n",
    "        Args:\n",
    "            x: original input, of shape (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        q = self.Wq(q) # (batch_size, seq_len_q, d_model)\n",
    "        k = self.Wq(k) # (batch_size, seq_len_k, d_model)\n",
    "        v = self.Wq(v) # (batch_size, seq_len_v, d_model)\n",
    "        \n",
    "        q = self.split_heads(q, batch_size) # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size) # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size) # (batch_size, num_heads, seq_len_v, depth)\n",
    "        \n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "        \n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3]) # (batch_size, seq_len_q, num_heads, depth)\n",
    "        concate_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))# (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        output = self.dense(concate_attention) # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
    "output, attention_weights = temp_mha(y, k=y, q=y, mask=None)\n",
    "output.shape, attention_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point wise feed forward network\n",
    "\n",
    "Point wise feed forward network consists of two fully-connected layers with a ReLU activation in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'), # (batch_size, seq_len, dff)\n",
    "        tf.keras.layers.Dense(d_model) # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder and decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](https://www.tensorflow.org/images/tutorials/transformer/transformer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder layer\n",
    "\n",
    "consists:\n",
    "- Multi-head attention (with padding mask)\n",
    "- Point wise feed forward networks\n",
    "\n",
    "Each of these sublayers has a residual connection around it followed by a layer normalization. Residual connections help in avoiding the vanishing gradient problem in deep networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1, **kwargs):\n",
    "        super(EncoderLayer, self).__init__(**kwargs)\n",
    "        \n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        \n",
    "        # The lower part\n",
    "        attn_output, _ = self.mha(x, x, x, mask) # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output) # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        # The upper part\n",
    "        ffn_output = self.ffn(out1) # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output) # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 40, 512])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(d_model=512, num_heads=8, dff=2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 40, 512)), training=False, mask=None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder layer\n",
    "\n",
    "consists:\n",
    "- Masked multi-head attention (with look ahead mask and padding mask)\n",
    "- Multi-head attention (with padding mask). V (value) and K (key) receive the encoder output as inputs. Q (query) receives the output from the masked multi-head attention sublayer.\n",
    "- Point wise feed forward networks\n",
    "\n",
    "Each of these sublayers has a residual connection around it followed by a layer normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1, **kwargs):\n",
    "        super(DecoderLayer, self).__init__(**kwargs)\n",
    "        \n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "        \n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        # The lower part\n",
    "        attn1, atten_weights_block1 = self.mha1(x, x, x, look_ahead_mask) # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x) # (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "        # The middle part\n",
    "        attn2, atten_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask) # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1) # (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "        # The upper part\n",
    "        ffn_output = self.ffn(out2) # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2) # (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "        return out3, atten_weights_block1, atten_weights_block2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(d_model=512, num_heads=8, dff=2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    x=tf.random.uniform((64, 50, 512)),\n",
    "    enc_output=sample_encoder_layer_output, \n",
    "    training=False,\n",
    "    look_ahead_mask=None,\n",
    "    padding_mask=None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "\n",
    "consist:\n",
    "- Input Embedding\n",
    "- Positional Embedding\n",
    "- N Encoder layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "                 maximum_position_encoding, rate=0.1, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, self.d_model) # (batch_size, input_seq_len, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model) # (1, max_pos_enc, d_model)\n",
    "        \n",
    "        self.enc_layers = [EncoderLayer(self.d_model, num_heads, dff, rate) for _ in range(self.num_layers)]\n",
    "        \n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        \n",
    "        seq_len = tf.shape(x)[1]\n",
    "        \n",
    "        # Adding embedding and position encoding.\n",
    "        x = self.embedding(x) # (batch_size, input_seq_len, d_model)\n",
    "        # The reason we increase the embedding values before the addition is to make \n",
    "        #   the positional encoding relatively smaller. This means the original meaning \n",
    "        #   in the embedding vector won’t be lost when we add them together.\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        \n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        for _ in range(self.num_layers):\n",
    "            x = self.enc_layers[_](x, training=training, mask=mask)\n",
    "            \n",
    "        return x # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, input_vocab_size=8500,\n",
    "                         maximum_position_encoding=10000)\n",
    "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
    "\n",
    "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "                 maximum_position_encoding, rate=0.1, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, self.d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
    "        \n",
    "        self.dec_layers = [DecoderLayer(self.d_model, num_heads, dff, rate) for _ in range(self.num_layers)]\n",
    "        \n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "        \n",
    "        x = self.embedding(x) # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        \n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        for _ in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[_](x, enc_output, training, look_ahead_mask, padding_mask)\n",
    "            \n",
    "            attention_weights['decoder_layer{}_block1'.format(_+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(_+1)] = block2\n",
    "            \n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, target_vocab_size=8000,\n",
    "                         maximum_position_encoding=5000)\n",
    "temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "output, attn = sample_decoder(temp_input, \n",
    "                              enc_output=sample_encoder_output, \n",
    "                              training=False,\n",
    "                              look_ahead_mask=None, \n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "                 target_vocab_size, pe_input, pe_target, rate=0.1, **kwargs):\n",
    "        super(Transformer, self).__init__(**kwargs)\n",
    "        \n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
    "        \n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "        \n",
    "    def call(self, inp, targ, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask) # (batch_size, input_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            targ, enc_output, training, look_ahead_mask, dec_padding_mask) # (batch_size, target_seq_len ,d_model)\n",
    "        \n",
    "        final_output = self.final_layer(dec_output) # (batch_size, target_seq_len, target_vocab_size)\n",
    "        \n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 36, 8000])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
    "    input_vocab_size=8500, target_vocab_size=8000, \n",
    "    pe_input=10000, pe_target=6000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
    "                               enc_padding_mask=None, \n",
    "                               look_ahead_mask=None,\n",
    "                               dec_padding_mask=None)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LAYERS = 8\n",
    "D_MODEL = 128\n",
    "DFF = 512\n",
    "NUM_HEADS = 8\n",
    "\n",
    "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
    "target_vocab_size = tokenizer_en.vocab_size + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000, **kwargs):\n",
    "        super(CustomSchedule, self).__init__(**kwargs)\n",
    "        \n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        \n",
    "        self.warmup_steps = warmup_steps\n",
    "        \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(D_MODEL)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(tf.math.not_equal(real, 0), loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_sum(loss_) / tf.reduce_sum(mask) # each token loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(NUM_LAYERS, D_MODEL, NUM_HEADS, DFF,\n",
    "                          input_vocab_size, target_vocab_size,\n",
    "                          pe_input=input_vocab_size,\n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(inp, targ):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "    \n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "    \n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(targ)[1]) # [target_seq_len, target_seq_len]\n",
    "    dec_target_padding_mask = create_padding_mask(targ) # [BATCH_SIZE, 1, 1, target_seq_len]\n",
    "    combind_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask) # [BATCH_SIZE, 1, target_seq_len, target_seq_len]\n",
    "    \n",
    "    return enc_padding_mask, combind_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = './checkpoint/train'\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target is divided into tar_inp and tar_real. tar_inp is passed as an input to the decoder. `tar_real` is that same input shifted by 1: At each location in `tar_input`, `tar_real` contains the next token that should be predicted.\n",
    "\n",
    "For example, `sentence` = \"SOS A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "`tar_inp` = \"SOS A lion in the jungle is sleeping\"\n",
    "\n",
    "`tar_real` = \"A lion in the jungle is sleeping EOS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformer is an auto-regressive model: it makes predictions one part at a time, and uses its output so far to decide what to do next.\n",
    "\n",
    "During training this example uses teacher-forcing. Teacher forcing is passing the true output to the next time step regardless of what the model predicts at the current time step.\n",
    "\n",
    "As the transformer predicts each word, self-attention allows it to look at the previous words in the input sequence to better predict the next word.\n",
    "\n",
    "To prevent the model from peaking at the expected output the model uses a look-ahead mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1] # (batch_size, target_seq_len - 1)\n",
    "    tar_real = tar[:, 1:] # (batch_size, target_seq_len - 1)\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_mask(inp, tar_inp)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp,\n",
    "                                     training=True, \n",
    "                                     enc_padding_mask=enc_padding_mask,\n",
    "                                     look_ahead_mask=combined_mask,\n",
    "                                     dec_padding_mask=dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "    \n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 9.0165 Accuracy 0.0000\n",
      "Epoch 1 Batch 50 Loss 7.0034 Accuracy 0.0248\n",
      "Epoch 1 Batch 100 Loss 6.7617 Accuracy 0.0258\n",
      "Epoch 1 Batch 150 Loss 6.6741 Accuracy 0.0261\n",
      "Epoch 1 Batch 200 Loss 6.6318 Accuracy 0.0263\n",
      "Epoch 1 Batch 250 Loss 6.6035 Accuracy 0.0265\n",
      "Epoch 1 Batch 300 Loss 6.5829 Accuracy 0.0266\n",
      "Epoch 1 Batch 350 Loss 6.5672 Accuracy 0.0266\n",
      "Epoch 1 Batch 400 Loss 6.5588 Accuracy 0.0266\n",
      "Epoch 1 Batch 450 Loss 6.5513 Accuracy 0.0266\n",
      "Epoch 1 Batch 500 Loss 6.5439 Accuracy 0.0267\n",
      "Epoch 1 Batch 550 Loss 6.5376 Accuracy 0.0267\n",
      "Epoch 1 Batch 600 Loss 6.5322 Accuracy 0.0267\n",
      "Epoch 1 Batch 650 Loss 6.5269 Accuracy 0.0267\n",
      "Epoch 1 Batch 700 Loss 6.5228 Accuracy 0.0268\n",
      "Saving checkpoint for epoch 1 at ./checkpoint/train/ckpt-5\n",
      "Epoch 1 Loss 6.5225 Accuracy 0.0268\n",
      "Time taken for 1 epoch: 90.27151536941528 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 6.4266 Accuracy 0.0274\n",
      "Epoch 2 Batch 50 Loss 6.4615 Accuracy 0.0271\n",
      "Epoch 2 Batch 100 Loss 6.4634 Accuracy 0.0272\n",
      "Epoch 2 Batch 150 Loss 6.4532 Accuracy 0.0275\n",
      "Epoch 2 Batch 200 Loss 6.4510 Accuracy 0.0276\n",
      "Epoch 2 Batch 250 Loss 6.4494 Accuracy 0.0278\n",
      "Epoch 2 Batch 300 Loss 6.4502 Accuracy 0.0278\n",
      "Epoch 2 Batch 350 Loss 6.4483 Accuracy 0.0280\n",
      "Epoch 2 Batch 400 Loss 6.4451 Accuracy 0.0283\n",
      "Epoch 2 Batch 450 Loss 6.4407 Accuracy 0.0286\n",
      "Epoch 2 Batch 500 Loss 6.4340 Accuracy 0.0290\n",
      "Epoch 2 Batch 550 Loss 6.4301 Accuracy 0.0294\n",
      "Epoch 2 Batch 600 Loss 6.4258 Accuracy 0.0297\n",
      "Epoch 2 Batch 650 Loss 6.4221 Accuracy 0.0301\n",
      "Epoch 2 Batch 700 Loss 6.4163 Accuracy 0.0305\n",
      "Epoch 2 Loss 6.4160 Accuracy 0.0305\n",
      "Time taken for 1 epoch: 74.33546829223633 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 6.3816 Accuracy 0.0377\n",
      "Epoch 3 Batch 50 Loss 6.3296 Accuracy 0.0350\n",
      "Epoch 3 Batch 100 Loss 6.3357 Accuracy 0.0356\n",
      "Epoch 3 Batch 150 Loss 6.3360 Accuracy 0.0357\n",
      "Epoch 3 Batch 200 Loss 6.3335 Accuracy 0.0358\n",
      "Epoch 3 Batch 250 Loss 6.3269 Accuracy 0.0361\n",
      "Epoch 3 Batch 300 Loss 6.3231 Accuracy 0.0364\n",
      "Epoch 3 Batch 350 Loss 6.3220 Accuracy 0.0366\n",
      "Epoch 3 Batch 400 Loss 6.3202 Accuracy 0.0369\n",
      "Epoch 3 Batch 450 Loss 6.3177 Accuracy 0.0370\n",
      "Epoch 3 Batch 500 Loss 6.3142 Accuracy 0.0372\n",
      "Epoch 3 Batch 550 Loss 6.3124 Accuracy 0.0373\n",
      "Epoch 3 Batch 600 Loss 6.3102 Accuracy 0.0374\n",
      "Epoch 3 Batch 650 Loss 6.3085 Accuracy 0.0376\n",
      "Epoch 3 Batch 700 Loss 6.3067 Accuracy 0.0377\n",
      "Epoch 3 Loss 6.3067 Accuracy 0.0377\n",
      "Time taken for 1 epoch: 74.33576726913452 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 6.2620 Accuracy 0.0411\n",
      "Epoch 4 Batch 50 Loss 6.2746 Accuracy 0.0391\n",
      "Epoch 4 Batch 100 Loss 6.2742 Accuracy 0.0391\n",
      "Epoch 4 Batch 150 Loss 6.2788 Accuracy 0.0391\n",
      "Epoch 4 Batch 200 Loss 6.2753 Accuracy 0.0393\n",
      "Epoch 4 Batch 250 Loss 6.2738 Accuracy 0.0394\n",
      "Epoch 4 Batch 300 Loss 6.2738 Accuracy 0.0395\n",
      "Epoch 4 Batch 350 Loss 6.2713 Accuracy 0.0395\n",
      "Epoch 4 Batch 400 Loss 6.2696 Accuracy 0.0396\n",
      "Epoch 4 Batch 450 Loss 6.2709 Accuracy 0.0397\n",
      "Epoch 4 Batch 500 Loss 6.2717 Accuracy 0.0397\n",
      "Epoch 4 Batch 550 Loss 6.2709 Accuracy 0.0397\n",
      "Epoch 4 Batch 600 Loss 6.2700 Accuracy 0.0397\n",
      "Epoch 4 Batch 650 Loss 6.2699 Accuracy 0.0397\n",
      "Epoch 4 Batch 700 Loss 6.2690 Accuracy 0.0397\n",
      "Epoch 4 Loss 6.2692 Accuracy 0.0397\n",
      "Time taken for 1 epoch: 74.72383308410645 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 6.1716 Accuracy 0.0451\n",
      "Epoch 5 Batch 50 Loss 6.2348 Accuracy 0.0404\n",
      "Epoch 5 Batch 100 Loss 6.2458 Accuracy 0.0405\n",
      "Epoch 5 Batch 150 Loss 6.2410 Accuracy 0.0409\n",
      "Epoch 5 Batch 200 Loss 6.2375 Accuracy 0.0412\n",
      "Epoch 5 Batch 250 Loss 6.2428 Accuracy 0.0411\n",
      "Epoch 5 Batch 300 Loss 6.2427 Accuracy 0.0413\n",
      "Epoch 5 Batch 350 Loss 6.2449 Accuracy 0.0413\n",
      "Epoch 5 Batch 400 Loss 6.2436 Accuracy 0.0414\n",
      "Epoch 5 Batch 450 Loss 6.2396 Accuracy 0.0415\n",
      "Epoch 5 Batch 500 Loss 6.2370 Accuracy 0.0416\n",
      "Epoch 5 Batch 550 Loss 6.2363 Accuracy 0.0417\n",
      "Epoch 5 Batch 600 Loss 6.2370 Accuracy 0.0416\n",
      "Epoch 5 Batch 650 Loss 6.2357 Accuracy 0.0418\n",
      "Epoch 5 Batch 700 Loss 6.2341 Accuracy 0.0419\n",
      "Epoch 5 Loss 6.2342 Accuracy 0.0419\n",
      "Time taken for 1 epoch: 74.47616124153137 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 6.2211 Accuracy 0.0421\n",
      "Epoch 6 Batch 50 Loss 6.2047 Accuracy 0.0442\n",
      "Epoch 6 Batch 100 Loss 6.2044 Accuracy 0.0438\n",
      "Epoch 6 Batch 150 Loss 6.2341 Accuracy 0.0417\n",
      "Epoch 6 Batch 200 Loss 6.2412 Accuracy 0.0412\n",
      "Epoch 6 Batch 250 Loss 6.2478 Accuracy 0.0411\n",
      "Epoch 6 Batch 300 Loss 6.2494 Accuracy 0.0410\n",
      "Epoch 6 Batch 350 Loss 6.2483 Accuracy 0.0410\n",
      "Epoch 6 Batch 400 Loss 6.2464 Accuracy 0.0410\n",
      "Epoch 6 Batch 450 Loss 6.2459 Accuracy 0.0410\n",
      "Epoch 6 Batch 500 Loss 6.2454 Accuracy 0.0410\n",
      "Epoch 6 Batch 550 Loss 6.2458 Accuracy 0.0410\n",
      "Epoch 6 Batch 600 Loss 6.2446 Accuracy 0.0410\n",
      "Epoch 6 Batch 650 Loss 6.2452 Accuracy 0.0409\n",
      "Epoch 6 Batch 700 Loss 6.2433 Accuracy 0.0409\n",
      "Saving checkpoint for epoch 6 at ./checkpoint/train/ckpt-6\n",
      "Epoch 6 Loss 6.2429 Accuracy 0.0409\n",
      "Time taken for 1 epoch: 74.4877290725708 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 6.2084 Accuracy 0.0387\n",
      "Epoch 7 Batch 50 Loss 6.2166 Accuracy 0.0410\n",
      "Epoch 7 Batch 100 Loss 6.2259 Accuracy 0.0410\n",
      "Epoch 7 Batch 150 Loss 6.2285 Accuracy 0.0413\n",
      "Epoch 7 Batch 200 Loss 6.2292 Accuracy 0.0414\n",
      "Epoch 7 Batch 250 Loss 6.2316 Accuracy 0.0414\n",
      "Epoch 7 Batch 300 Loss 6.2320 Accuracy 0.0415\n",
      "Epoch 7 Batch 350 Loss 6.2314 Accuracy 0.0415\n",
      "Epoch 7 Batch 400 Loss 6.2277 Accuracy 0.0416\n",
      "Epoch 7 Batch 450 Loss 6.2301 Accuracy 0.0415\n",
      "Epoch 7 Batch 500 Loss 6.2309 Accuracy 0.0415\n",
      "Epoch 7 Batch 550 Loss 6.2309 Accuracy 0.0415\n",
      "Epoch 7 Batch 600 Loss 6.2305 Accuracy 0.0414\n",
      "Epoch 7 Batch 650 Loss 6.2307 Accuracy 0.0415\n",
      "Epoch 7 Batch 700 Loss 6.2308 Accuracy 0.0416\n",
      "Epoch 7 Loss 6.2306 Accuracy 0.0416\n",
      "Time taken for 1 epoch: 74.14487624168396 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 6.0898 Accuracy 0.0511\n",
      "Epoch 8 Batch 50 Loss 6.2175 Accuracy 0.0425\n",
      "Epoch 8 Batch 100 Loss 6.2261 Accuracy 0.0422\n",
      "Epoch 8 Batch 150 Loss 6.2220 Accuracy 0.0417\n",
      "Epoch 8 Batch 200 Loss 6.2217 Accuracy 0.0419\n",
      "Epoch 8 Batch 250 Loss 6.2217 Accuracy 0.0417\n",
      "Epoch 8 Batch 300 Loss 6.2208 Accuracy 0.0418\n",
      "Epoch 8 Batch 350 Loss 6.2198 Accuracy 0.0418\n",
      "Epoch 8 Batch 400 Loss 6.2211 Accuracy 0.0418\n",
      "Epoch 8 Batch 450 Loss 6.2213 Accuracy 0.0418\n",
      "Epoch 8 Batch 500 Loss 6.2215 Accuracy 0.0418\n",
      "Epoch 8 Batch 550 Loss 6.2217 Accuracy 0.0418\n",
      "Epoch 8 Batch 600 Loss 6.2216 Accuracy 0.0419\n",
      "Epoch 8 Batch 650 Loss 6.2211 Accuracy 0.0419\n",
      "Epoch 8 Batch 700 Loss 6.2217 Accuracy 0.0420\n",
      "Epoch 8 Loss 6.2219 Accuracy 0.0420\n",
      "Time taken for 1 epoch: 74.46008038520813 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 6.1696 Accuracy 0.0437\n",
      "Epoch 9 Batch 50 Loss 6.2035 Accuracy 0.0430\n",
      "Epoch 9 Batch 100 Loss 6.2172 Accuracy 0.0427\n",
      "Epoch 9 Batch 150 Loss 6.2005 Accuracy 0.0429\n",
      "Epoch 9 Batch 200 Loss 6.2022 Accuracy 0.0428\n",
      "Epoch 9 Batch 250 Loss 6.2011 Accuracy 0.0427\n",
      "Epoch 9 Batch 300 Loss 6.2007 Accuracy 0.0428\n",
      "Epoch 9 Batch 350 Loss 6.2030 Accuracy 0.0427\n",
      "Epoch 9 Batch 400 Loss 6.2051 Accuracy 0.0427\n",
      "Epoch 9 Batch 450 Loss 6.2024 Accuracy 0.0427\n",
      "Epoch 9 Batch 500 Loss 6.2046 Accuracy 0.0429\n",
      "Epoch 9 Batch 550 Loss 6.2055 Accuracy 0.0429\n",
      "Epoch 9 Batch 600 Loss 6.2067 Accuracy 0.0429\n",
      "Epoch 9 Batch 650 Loss 6.2082 Accuracy 0.0427\n",
      "Epoch 9 Batch 700 Loss 6.2093 Accuracy 0.0427\n",
      "Epoch 9 Loss 6.2092 Accuracy 0.0427\n",
      "Time taken for 1 epoch: 74.67027568817139 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 6.0806 Accuracy 0.0428\n",
      "Epoch 10 Batch 50 Loss 6.1960 Accuracy 0.0430\n",
      "Epoch 10 Batch 100 Loss 6.1966 Accuracy 0.0434\n",
      "Epoch 10 Batch 150 Loss 6.1951 Accuracy 0.0433\n",
      "Epoch 10 Batch 200 Loss 6.2003 Accuracy 0.0430\n",
      "Epoch 10 Batch 250 Loss 6.2023 Accuracy 0.0427\n",
      "Epoch 10 Batch 300 Loss 6.1985 Accuracy 0.0429\n",
      "Epoch 10 Batch 350 Loss 6.1956 Accuracy 0.0429\n",
      "Epoch 10 Batch 400 Loss 6.1964 Accuracy 0.0428\n",
      "Epoch 10 Batch 450 Loss 6.1980 Accuracy 0.0429\n",
      "Epoch 10 Batch 500 Loss 6.2011 Accuracy 0.0429\n",
      "Epoch 10 Batch 550 Loss 6.2000 Accuracy 0.0428\n",
      "Epoch 10 Batch 600 Loss 6.2005 Accuracy 0.0429\n",
      "Epoch 10 Batch 650 Loss 6.2016 Accuracy 0.0430\n",
      "Epoch 10 Batch 700 Loss 6.2012 Accuracy 0.0430\n",
      "Epoch 10 Loss 6.2011 Accuracy 0.0430\n",
      "Time taken for 1 epoch: 74.21350121498108 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 6.2686 Accuracy 0.0428\n",
      "Epoch 11 Batch 50 Loss 6.1857 Accuracy 0.0429\n",
      "Epoch 11 Batch 100 Loss 6.1830 Accuracy 0.0429\n",
      "Epoch 11 Batch 150 Loss 6.1839 Accuracy 0.0431\n",
      "Epoch 11 Batch 200 Loss 6.1827 Accuracy 0.0433\n",
      "Epoch 11 Batch 250 Loss 6.1846 Accuracy 0.0434\n",
      "Epoch 11 Batch 300 Loss 6.1859 Accuracy 0.0434\n",
      "Epoch 11 Batch 350 Loss 6.1860 Accuracy 0.0434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Batch 400 Loss 6.1885 Accuracy 0.0434\n",
      "Epoch 11 Batch 450 Loss 6.1890 Accuracy 0.0435\n",
      "Epoch 11 Batch 500 Loss 6.1890 Accuracy 0.0434\n",
      "Epoch 11 Batch 550 Loss 6.1902 Accuracy 0.0435\n",
      "Epoch 11 Batch 600 Loss 6.1923 Accuracy 0.0435\n",
      "Epoch 11 Batch 650 Loss 6.1918 Accuracy 0.0435\n",
      "Epoch 11 Batch 700 Loss 6.1924 Accuracy 0.0435\n",
      "Saving checkpoint for epoch 11 at ./checkpoint/train/ckpt-7\n",
      "Epoch 11 Loss 6.1925 Accuracy 0.0435\n",
      "Time taken for 1 epoch: 74.77364444732666 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 6.2430 Accuracy 0.0421\n",
      "Epoch 12 Batch 50 Loss 6.1678 Accuracy 0.0442\n",
      "Epoch 12 Batch 100 Loss 6.1807 Accuracy 0.0437\n",
      "Epoch 12 Batch 150 Loss 6.1826 Accuracy 0.0435\n",
      "Epoch 12 Batch 200 Loss 6.1816 Accuracy 0.0435\n",
      "Epoch 12 Batch 250 Loss 6.1821 Accuracy 0.0435\n",
      "Epoch 12 Batch 300 Loss 6.1832 Accuracy 0.0433\n",
      "Epoch 12 Batch 350 Loss 6.1845 Accuracy 0.0434\n",
      "Epoch 12 Batch 400 Loss 6.1855 Accuracy 0.0435\n",
      "Epoch 12 Batch 450 Loss 6.1850 Accuracy 0.0434\n",
      "Epoch 12 Batch 500 Loss 6.1857 Accuracy 0.0435\n",
      "Epoch 12 Batch 550 Loss 6.1883 Accuracy 0.0435\n",
      "Epoch 12 Batch 600 Loss 6.1875 Accuracy 0.0435\n",
      "Epoch 12 Batch 650 Loss 6.1856 Accuracy 0.0437\n",
      "Epoch 12 Batch 700 Loss 6.1855 Accuracy 0.0437\n",
      "Epoch 12 Loss 6.1855 Accuracy 0.0437\n",
      "Time taken for 1 epoch: 74.40181565284729 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 6.1715 Accuracy 0.0449\n",
      "Epoch 13 Batch 50 Loss 6.1834 Accuracy 0.0436\n",
      "Epoch 13 Batch 100 Loss 6.1828 Accuracy 0.0440\n",
      "Epoch 13 Batch 150 Loss 6.1830 Accuracy 0.0441\n",
      "Epoch 13 Batch 200 Loss 6.1779 Accuracy 0.0444\n",
      "Epoch 13 Batch 250 Loss 6.1775 Accuracy 0.0441\n",
      "Epoch 13 Batch 300 Loss 6.1790 Accuracy 0.0441\n",
      "Epoch 13 Batch 350 Loss 6.1793 Accuracy 0.0440\n",
      "Epoch 13 Batch 400 Loss 6.1793 Accuracy 0.0440\n",
      "Epoch 13 Batch 450 Loss 6.1800 Accuracy 0.0441\n",
      "Epoch 13 Batch 500 Loss 6.1824 Accuracy 0.0441\n",
      "Epoch 13 Batch 550 Loss 6.1835 Accuracy 0.0441\n",
      "Epoch 13 Batch 600 Loss 6.1822 Accuracy 0.0440\n",
      "Epoch 13 Batch 650 Loss 6.1826 Accuracy 0.0441\n",
      "Epoch 13 Batch 700 Loss 6.1818 Accuracy 0.0440\n",
      "Epoch 13 Loss 6.1816 Accuracy 0.0441\n",
      "Time taken for 1 epoch: 74.7404236793518 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 6.1841 Accuracy 0.0464\n",
      "Epoch 14 Batch 50 Loss 6.1715 Accuracy 0.0443\n",
      "Epoch 14 Batch 100 Loss 6.1657 Accuracy 0.0441\n",
      "Epoch 14 Batch 150 Loss 6.1689 Accuracy 0.0441\n",
      "Epoch 14 Batch 200 Loss 6.1687 Accuracy 0.0440\n",
      "Epoch 14 Batch 250 Loss 6.1696 Accuracy 0.0440\n",
      "Epoch 14 Batch 300 Loss 6.1719 Accuracy 0.0439\n",
      "Epoch 14 Batch 350 Loss 6.1747 Accuracy 0.0438\n",
      "Epoch 14 Batch 400 Loss 6.1758 Accuracy 0.0440\n",
      "Epoch 14 Batch 450 Loss 6.1768 Accuracy 0.0440\n",
      "Epoch 14 Batch 500 Loss 6.1780 Accuracy 0.0440\n",
      "Epoch 14 Batch 550 Loss 6.1787 Accuracy 0.0441\n",
      "Epoch 14 Batch 600 Loss 6.1789 Accuracy 0.0440\n",
      "Epoch 14 Batch 650 Loss 6.1773 Accuracy 0.0441\n",
      "Epoch 14 Batch 700 Loss 6.1790 Accuracy 0.0441\n",
      "Epoch 14 Loss 6.1790 Accuracy 0.0441\n",
      "Time taken for 1 epoch: 74.13521456718445 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 5.9996 Accuracy 0.0451\n",
      "Epoch 15 Batch 50 Loss 6.1506 Accuracy 0.0448\n",
      "Epoch 15 Batch 100 Loss 6.1529 Accuracy 0.0458\n",
      "Epoch 15 Batch 150 Loss 6.1576 Accuracy 0.0464\n",
      "Epoch 15 Batch 200 Loss 6.1532 Accuracy 0.0476\n",
      "Epoch 15 Batch 250 Loss 6.1510 Accuracy 0.0488\n",
      "Epoch 15 Batch 300 Loss 6.1486 Accuracy 0.0501\n",
      "Epoch 15 Batch 350 Loss 6.1473 Accuracy 0.0512\n",
      "Epoch 15 Batch 400 Loss 6.1425 Accuracy 0.0522\n",
      "Epoch 15 Batch 450 Loss 6.1378 Accuracy 0.0530\n",
      "Epoch 15 Batch 500 Loss 6.1344 Accuracy 0.0537\n",
      "Epoch 15 Batch 550 Loss 6.1307 Accuracy 0.0541\n",
      "Epoch 15 Batch 600 Loss 6.1290 Accuracy 0.0544\n",
      "Epoch 15 Batch 650 Loss 6.1268 Accuracy 0.0548\n",
      "Epoch 15 Batch 700 Loss 6.1255 Accuracy 0.0550\n",
      "Epoch 15 Loss 6.1255 Accuracy 0.0550\n",
      "Time taken for 1 epoch: 74.26576113700867 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 6.1158 Accuracy 0.0533\n",
      "Epoch 16 Batch 50 Loss 6.0761 Accuracy 0.0588\n",
      "Epoch 16 Batch 100 Loss 6.0867 Accuracy 0.0587\n",
      "Epoch 16 Batch 150 Loss 6.0843 Accuracy 0.0587\n",
      "Epoch 16 Batch 200 Loss 6.0841 Accuracy 0.0587\n",
      "Epoch 16 Batch 250 Loss 6.0813 Accuracy 0.0586\n",
      "Epoch 16 Batch 300 Loss 6.0855 Accuracy 0.0581\n",
      "Epoch 16 Batch 350 Loss 6.0882 Accuracy 0.0569\n",
      "Epoch 16 Batch 400 Loss 6.0889 Accuracy 0.0564\n",
      "Epoch 16 Batch 450 Loss 6.0879 Accuracy 0.0564\n",
      "Epoch 16 Batch 500 Loss 6.0903 Accuracy 0.0563\n",
      "Epoch 16 Batch 550 Loss 6.0895 Accuracy 0.0562\n",
      "Epoch 16 Batch 600 Loss 6.0895 Accuracy 0.0560\n",
      "Epoch 16 Batch 650 Loss 6.0893 Accuracy 0.0562\n",
      "Epoch 16 Batch 700 Loss 6.0886 Accuracy 0.0564\n",
      "Saving checkpoint for epoch 16 at ./checkpoint/train/ckpt-8\n",
      "Epoch 16 Loss 6.0886 Accuracy 0.0564\n",
      "Time taken for 1 epoch: 74.83199620246887 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 6.1344 Accuracy 0.0498\n",
      "Epoch 17 Batch 50 Loss 6.0905 Accuracy 0.0543\n",
      "Epoch 17 Batch 100 Loss 6.0741 Accuracy 0.0562\n",
      "Epoch 17 Batch 150 Loss 6.0689 Accuracy 0.0563\n",
      "Epoch 17 Batch 200 Loss 6.0740 Accuracy 0.0562\n",
      "Epoch 17 Batch 250 Loss 6.0774 Accuracy 0.0562\n",
      "Epoch 17 Batch 300 Loss 6.0817 Accuracy 0.0555\n",
      "Epoch 17 Batch 350 Loss 6.0830 Accuracy 0.0551\n",
      "Epoch 17 Batch 400 Loss 6.0814 Accuracy 0.0549\n",
      "Epoch 17 Batch 450 Loss 6.0835 Accuracy 0.0547\n",
      "Epoch 17 Batch 500 Loss 6.0837 Accuracy 0.0546\n",
      "Epoch 17 Batch 550 Loss 6.0864 Accuracy 0.0549\n",
      "Epoch 17 Batch 600 Loss 6.0840 Accuracy 0.0555\n",
      "Epoch 17 Batch 650 Loss 6.0838 Accuracy 0.0560\n",
      "Epoch 17 Batch 700 Loss 6.0858 Accuracy 0.0559\n",
      "Epoch 17 Loss 6.0860 Accuracy 0.0559\n",
      "Time taken for 1 epoch: 74.64208221435547 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 6.2118 Accuracy 0.0530\n",
      "Epoch 18 Batch 50 Loss 6.1082 Accuracy 0.0546\n",
      "Epoch 18 Batch 100 Loss 6.0878 Accuracy 0.0562\n",
      "Epoch 18 Batch 150 Loss 6.0981 Accuracy 0.0556\n",
      "Epoch 18 Batch 200 Loss 6.0941 Accuracy 0.0547\n",
      "Epoch 18 Batch 250 Loss 6.1024 Accuracy 0.0536\n",
      "Epoch 18 Batch 300 Loss 6.1156 Accuracy 0.0522\n",
      "Epoch 18 Batch 350 Loss 6.1252 Accuracy 0.0509\n",
      "Epoch 18 Batch 400 Loss 6.1313 Accuracy 0.0501\n",
      "Epoch 18 Batch 450 Loss 6.1339 Accuracy 0.0495\n",
      "Epoch 18 Batch 500 Loss 6.1381 Accuracy 0.0489\n",
      "Epoch 18 Batch 550 Loss 6.1415 Accuracy 0.0484\n",
      "Epoch 18 Batch 600 Loss 6.1450 Accuracy 0.0481\n",
      "Epoch 18 Batch 650 Loss 6.1485 Accuracy 0.0477\n",
      "Epoch 18 Batch 700 Loss 6.1508 Accuracy 0.0475\n",
      "Epoch 18 Loss 6.1508 Accuracy 0.0475\n",
      "Time taken for 1 epoch: 74.27783799171448 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 6.2135 Accuracy 0.0429\n",
      "Epoch 19 Batch 50 Loss 6.1795 Accuracy 0.0446\n",
      "Epoch 19 Batch 100 Loss 6.1685 Accuracy 0.0453\n",
      "Epoch 19 Batch 150 Loss 6.1690 Accuracy 0.0450\n",
      "Epoch 19 Batch 200 Loss 6.1684 Accuracy 0.0452\n",
      "Epoch 19 Batch 250 Loss 6.1644 Accuracy 0.0450\n",
      "Epoch 19 Batch 300 Loss 6.1654 Accuracy 0.0449\n",
      "Epoch 19 Batch 350 Loss 6.1653 Accuracy 0.0448\n",
      "Epoch 19 Batch 400 Loss 6.1655 Accuracy 0.0449\n",
      "Epoch 19 Batch 450 Loss 6.1658 Accuracy 0.0448\n",
      "Epoch 19 Batch 500 Loss 6.1635 Accuracy 0.0452\n",
      "Epoch 19 Batch 550 Loss 6.1577 Accuracy 0.0457\n",
      "Epoch 19 Batch 600 Loss 6.1499 Accuracy 0.0463\n",
      "Epoch 19 Batch 650 Loss 6.1438 Accuracy 0.0472\n",
      "Epoch 19 Batch 700 Loss 6.1405 Accuracy 0.0480\n",
      "Epoch 19 Loss 6.1402 Accuracy 0.0480\n",
      "Time taken for 1 epoch: 74.42671632766724 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 6.1178 Accuracy 0.0688\n",
      "Epoch 20 Batch 50 Loss 6.0623 Accuracy 0.0574\n",
      "Epoch 20 Batch 100 Loss 6.0578 Accuracy 0.0567\n",
      "Epoch 20 Batch 150 Loss 6.0655 Accuracy 0.0554\n",
      "Epoch 20 Batch 200 Loss 6.0624 Accuracy 0.0545\n",
      "Epoch 20 Batch 250 Loss 6.0588 Accuracy 0.0537\n",
      "Epoch 20 Batch 300 Loss 6.0614 Accuracy 0.0533\n",
      "Epoch 20 Batch 350 Loss 6.0639 Accuracy 0.0527\n",
      "Epoch 20 Batch 400 Loss 6.0612 Accuracy 0.0525\n",
      "Epoch 20 Batch 450 Loss 6.0588 Accuracy 0.0524\n",
      "Epoch 20 Batch 500 Loss 6.0602 Accuracy 0.0522\n",
      "Epoch 20 Batch 550 Loss 6.0597 Accuracy 0.0521\n",
      "Epoch 20 Batch 600 Loss 6.0596 Accuracy 0.0520\n",
      "Epoch 20 Batch 650 Loss 6.0604 Accuracy 0.0519\n",
      "Epoch 20 Batch 700 Loss 6.0589 Accuracy 0.0518\n",
      "Epoch 20 Loss 6.0585 Accuracy 0.0518\n",
      "Time taken for 1 epoch: 74.25125861167908 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    \n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    \n",
    "    # inp -> portuguese, targ -> english\n",
    "    for (batch_idx, (inp, targ)) in enumerate(train_dataset):\n",
    "        train_step(inp, targ)\n",
    "        \n",
    "        if batch_idx % 50 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch+1, batch_idx, train_loss.result(), train_accuracy.result()))\n",
    "            \n",
    "    if epoch % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
    "        \n",
    "    print('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch+1, train_loss.result(), train_accuracy.result()))\n",
    "    print('Time taken for 1 epoch: {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "    start_token = [tokenizer_pt.vocab_size]\n",
    "    end_token = [tokenizer_pt.vocab_size + 1]\n",
    "    \n",
    "    # inp sentence is portuguese, hence adding the start and end token\n",
    "    inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
    "    encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "    \n",
    "    # as the target is english, the first word to the transformer should be english start token.\n",
    "    decoder_input = [tokenizer_en.vocab_size]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "    for i in range(MAX_LENGTH):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_mask(encoder_input, output)\n",
    "        \n",
    "        # predictions.shape == [batch_size(1), seq_len, vocab_size]\n",
    "        predictions, attention_weights = transformer(encoder_input,\n",
    "                                                     output,\n",
    "                                                     False,\n",
    "                                                     enc_padding_mask,\n",
    "                                                     combined_mask,\n",
    "                                                     dec_padding_mask)\n",
    "        \n",
    "        # select the last word from the seq_len dimension\n",
    "        predictions = predictions[:, -1:, :] # [batch_size(1), 1, vocab_size]\n",
    "        \n",
    "        prediction_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32) # [batch_size(1), 1]\n",
    "        \n",
    "        # return the result if the predicted_id is equal to the end token\n",
    "        if prediction_id == tokenizer_en.vocab_size + 1:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "        else:\n",
    "            output = tf.concat([output, prediction_id], axis=-1)\n",
    "            \n",
    "    return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "    sentence = tokenizer_pt.encode(sentence)\n",
    "\n",
    "    attention = tf.squeeze(attention[layer], axis=0)\n",
    "\n",
    "    for head in range(attention.shape[0]):\n",
    "        ax = fig.add_subplot(2, 4, head+1)\n",
    "\n",
    "        # plot the attention weights\n",
    "        ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "        fontdict = {'fontsize': 10}\n",
    "\n",
    "        ax.set_xticks(range(len(sentence)+2))\n",
    "        ax.set_yticks(range(len(result)))\n",
    "\n",
    "        ax.set_ylim(len(result)-1.5, -0.5)\n",
    "\n",
    "        ax.set_xticklabels(\n",
    "            ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
    "            fontdict=fontdict, rotation=90)\n",
    "\n",
    "        ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
    "                            if i < tokenizer_en.vocab_size], \n",
    "                           fontdict=fontdict)\n",
    "\n",
    "        ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, plot=''):\n",
    "    result, attention_weights = evaluate(sentence)\n",
    "\n",
    "    predicted_sentence = tokenizer_en.decode([i for i in result \n",
    "                                            if i < tokenizer_en.vocab_size])  \n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(predicted_sentence))\n",
    "\n",
    "    if plot:\n",
    "        plot_attention_weights(attention_weights, sentence, result, plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: este é um problema que temos que resolver.\n",
      "Predicted translation: thank thank \n",
      "Real translation: this is a problem we have to solve .\n"
     ]
    }
   ],
   "source": [
    "translate(\"este é um problema que temos que resolver.\")\n",
    "print (\"Real translation: this is a problem we have to solve .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: os meus vizinhos ouviram sobre esta ideia.\n",
      "Predicted translation: thank \n",
      "Real translation: and my neighboring homes heard about this idea .\n"
     ]
    }
   ],
   "source": [
    "translate(\"os meus vizinhos ouviram sobre esta ideia.\")\n",
    "print (\"Real translation: and my neighboring homes heard about this idea .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\n",
      "Predicted translation: thank \n",
      "Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\n"
     ]
    }
   ],
   "source": [
    "translate(\"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\")\n",
    "print (\"Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: este é o primeiro livro que eu fiz.\n",
      "Predicted translation: thank thank \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real translation: this is the first book i've ever done.\n"
     ]
    }
   ],
   "source": [
    "translate(\"este é o primeiro livro que eu fiz.\", plot='decoder_layer4_block2')\n",
    "print (\"Real translation: this is the first book i've ever done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
