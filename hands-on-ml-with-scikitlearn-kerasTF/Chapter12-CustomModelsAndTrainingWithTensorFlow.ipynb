{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#A-Quick-Tour-of-TensorFlow\" data-toc-modified-id=\"A-Quick-Tour-of-TensorFlow-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>A Quick Tour of TensorFlow</a></span></li><li><span><a href=\"#Using-TensorFlow-like-NumPy\" data-toc-modified-id=\"Using-TensorFlow-like-NumPy-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Using TensorFlow like NumPy</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tensors-and-Operations\" data-toc-modified-id=\"Tensors-and-Operations-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Tensors and Operations</a></span></li><li><span><a href=\"#Tensors-and-NumPy\" data-toc-modified-id=\"Tensors-and-NumPy-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Tensors and NumPy</a></span></li><li><span><a href=\"#Type-Conversions\" data-toc-modified-id=\"Type-Conversions-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Type Conversions</a></span></li><li><span><a href=\"#Variables\" data-toc-modified-id=\"Variables-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Variables</a></span></li><li><span><a href=\"#Other-Data-Structures\" data-toc-modified-id=\"Other-Data-Structures-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Other Data Structures</a></span></li></ul></li><li><span><a href=\"#Customizing-Models-and-Training-Algorithms\" data-toc-modified-id=\"Customizing-Models-and-Training-Algorithms-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Customizing Models and Training Algorithms</a></span><ul class=\"toc-item\"><li><span><a href=\"#Custom-Loss-Functions\" data-toc-modified-id=\"Custom-Loss-Functions-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Custom Loss Functions</a></span></li><li><span><a href=\"#Saving-and-Loading-Models-That-Contains-Custom-Components\" data-toc-modified-id=\"Saving-and-Loading-Models-That-Contains-Custom-Components-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Saving and Loading Models That Contains Custom Components</a></span></li><li><span><a href=\"#Custom-Activation-Functions,-Initializers,-Regularizers,-and-Constraints\" data-toc-modified-id=\"Custom-Activation-Functions,-Initializers,-Regularizers,-and-Constraints-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Custom Activation Functions, Initializers, Regularizers, and Constraints</a></span></li><li><span><a href=\"#Custom-Metrics\" data-toc-modified-id=\"Custom-Metrics-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Custom Metrics</a></span></li><li><span><a href=\"#Custom-Layers\" data-toc-modified-id=\"Custom-Layers-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Custom Layers</a></span></li><li><span><a href=\"#Custom-Models\" data-toc-modified-id=\"Custom-Models-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Custom Models</a></span></li><li><span><a href=\"#Losses-and-Metrics-Based-on-Model-Internals\" data-toc-modified-id=\"Losses-and-Metrics-Based-on-Model-Internals-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>Losses and Metrics Based on Model Internals</a></span></li><li><span><a href=\"#Computing-Gradients-Using-Autodiff\" data-toc-modified-id=\"Computing-Gradients-Using-Autodiff-3.8\"><span class=\"toc-item-num\">3.8&nbsp;&nbsp;</span>Computing Gradients Using Autodiff</a></span></li><li><span><a href=\"#Custom-Training-Loops\" data-toc-modified-id=\"Custom-Training-Loops-3.9\"><span class=\"toc-item-num\">3.9&nbsp;&nbsp;</span>Custom Training Loops</a></span></li></ul></li><li><span><a href=\"#TensorFlow-Functions-and-Graphs\" data-toc-modified-id=\"TensorFlow-Functions-and-Graphs-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>TensorFlow Functions and Graphs</a></span><ul class=\"toc-item\"><li><span><a href=\"#AutoGraph-and-Tracing\" data-toc-modified-id=\"AutoGraph-and-Tracing-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>AutoGraph and Tracing</a></span></li><li><span><a href=\"#TF-Function-Rules\" data-toc-modified-id=\"TF-Function-Rules-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>TF Function Rules</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Quick Tour of TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High-level DL APIs\n",
    "- tf.keras\n",
    "- tf.estimator\n",
    "\n",
    "Low-level DL APIs\n",
    "- tf.nn\n",
    "- tf.losses\n",
    "- tf.metrics\n",
    "- tf.optimizers\n",
    "- tf.train\n",
    "- tf.initializers\n",
    "\n",
    "Autodiff\n",
    "- tf.GradientTape\n",
    "- tf.gradients()\n",
    "\n",
    "I/O and preprocessing\n",
    "- tf.data\n",
    "- tf.feature_column\n",
    "- tf.audio\n",
    "- tf.image\n",
    "- tf.io\n",
    "- tf.queue\n",
    "\n",
    "Visualization with TensorBoard\n",
    "- tf.summary\n",
    "\n",
    "Deployment and optimization\n",
    "- tf.distribute\n",
    "- tf.saved_model\n",
    "- tf.autograph\n",
    "- tf.graph_util\n",
    "- tf.lite\n",
    "- tf.quantization\n",
    "- tf.tpu\n",
    "- tf.xla\n",
    "\n",
    "Special data structures\n",
    "- tf.lookup\n",
    "- tf.nest\n",
    "- tf.ragged\n",
    "- tf.sets\n",
    "- tf.sparse\n",
    "- tf.strings\n",
    "\n",
    "Mathematics, including linear algebraand signal processing\n",
    "- tf.math\n",
    "- tf.linalg\n",
    "- tf.signal\n",
    "- tf.random\n",
    "- tf.bitwise\n",
    "\n",
    "Miscellaneous\n",
    "- tf.compat\n",
    "- tf.config\n",
    "\n",
    "& more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TensorFlow like NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors and Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [3., 4., 5.]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([[1,2,3.], [3,4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.constant([[1.,2.,3.,], [4.,5.,6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [5.]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:, 1, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t @ tf.transpose(t) # @ is matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OR\n",
    "tf.matmul(t, tf.transpose(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors and NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([2., 4., 5.], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([2.,4.,5.])\n",
    "tf.constant(a, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 4., 16., 25.], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(a.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.errors import InvalidArgumentError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF do not perform any type conversion automatically\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=3>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    tf.constant(2.) + tf.constant(1)\n",
    "except InvalidArgumentError:\n",
    "    print('TF do not perform any type conversion automatically')\n",
    "    \n",
    "tf.constant(2) + tf.constant(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 cannot add float64 automatically\n"
     ]
    }
   ],
   "source": [
    "t2 = tf.constant(40, dtype=tf.float64)\n",
    "try:\n",
    "    tf.constant(2.0) + t2\n",
    "except InvalidArgumentError:\n",
    "    print(\"float32 cannot add float64 automatically\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(2.) + tf.cast(t2, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can be mutable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.Variable([[1.,2.,3.], [4.,5.,6.]], dtype=tf.float32)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[2., 3., 4.],\n",
       "       [5., 6., 7.]], dtype=float32)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign_add(np.ones((2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 4.,  6.,  8.],\n",
       "       [10., 12., 14.]], dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign(2 * v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 4., 42.,  8.],\n",
       "       [10., 12., 14.]], dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0, 1].assign(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 4., 42.,  0.],\n",
       "       [10., 12.,  1.]], dtype=float32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[:, 2].assign([0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[100.,  42.,   0.],\n",
       "       [ 10.,  12., 200.]], dtype=float32)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.scatter_nd_update(indices=[[0, 0], [1,2]], updates=[100, 200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spare tensor: efficiently represent tensors containing mostly zeros.\n",
    "# tf.sparse contains operations for sparse tensors\n",
    "tf.SparseTensor\n",
    "\n",
    "# tensor array: lists of tensors. All tensors must have the same shape and data type.\n",
    "tf.TensorArray\n",
    "\n",
    "# ragged tensors: represents static lists of lists of tensors, every tensor has the same shape and data type.\n",
    "# tf.ragged contains operations for ragged tensors\n",
    "tf.RaggedTensor\n",
    "\n",
    "# strinf tensors\n",
    "tf.string\n",
    "\n",
    "# sets\n",
    "tf.sets\n",
    "\n",
    "# queues\n",
    "tf.queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing Models and Training Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Custom Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.losses.Huber()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "loss = 0.5 * x^2                  if |x| <= d\n",
    "loss = 0.5 * d^2 + d * (|x| - d)  if |x| > d\n",
    "\n",
    "where x is y_true - y_pred;\n",
    "d is delta, a hyperparameter \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement Huber loss\n",
    "def huber_fn(y_true, y_pred):\n",
    "    delta = 1.0\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) <= delta\n",
    "    squared_loss = tf.square(error) * 0.5\n",
    "    linear_loss = 0.5 * delta**2 + delta * (tf.abs(error) - delta)\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=huber_fn, optimizer='nadam')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Loading Models That Contains Custom Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"path_to_model\", custom_objects={'huber_fn': huber_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different threshold\n",
    "def create_huber(delta=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) <= delta\n",
    "        squared_loss = tf.square(error) * 0.5\n",
    "        linear_loss = 0.5 * delta**2 + delta * (tf.abs(error) - delta)\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(3.0), optimizer='nadam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('path_to_model', custom_objects={'huber_fn': create_huber(3.0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## another way is to use subclass\n",
    "class HuberLoss(keras.losses.Loss):\n",
    "    def __init__(self, delta=1.0, **kwargs):\n",
    "        self.delta = delta\n",
    "        super(HuberLoss, self).__init__(**kwargs)\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) <= delta\n",
    "        squared_loss = tf.square(error) * 0.5\n",
    "        linear_loss = 0.5 * delta**2 + delta * (tf.abs(error) - delta)\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    def get_config(self):\n",
    "        base_config = super(HuberLoss, self).get_config()\n",
    "        return {**base_config, \"delta\": self.delta}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=HuberLoss(2.), optimizer='nadam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('path_to_model', custom_objects={'HuberLoss': HuberLoss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Activation Functions, Initializers, Regularizers, and Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z):\n",
    "    return tf.math.log(tf.exp(z) + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `stddev = sqrt(2 / (fan_in + fan_out))`\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2.0 / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_l1_regularizer(weights):\n",
    "    alpha = 0.01\n",
    "    return tf.reduce_sum(tf.math.abs(alpha * weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return value is just tf.nn.relu(weights)\n",
    "def my_positive_weights(weights):\n",
    "    return tf.where(weights<0, tf.zeros_like(weights), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(30, \n",
    "                           activation=my_softplus, \n",
    "                           kernel_initializer=my_glorot_initializer,\n",
    "                           kernel_regularizer=my_l1_regularizer,\n",
    "                           kernel_constraint=my_positive_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If want to save the hyperparameter in customized components, need to subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, alpha, **kwargs):\n",
    "        self.alpha = alpha\n",
    "        super(MyL1Regularizer, self).__init__(**kwargs)\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.math.abs(self.alpha * weights))\n",
    "    def get_config(self):\n",
    "        base_config = super(MyL1Regularizer, self).get_config()\n",
    "        return {**base_config, \"alpha\": self.alpha}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: initializer, regularizer, constraint implement \\__call__(), while for layers, losses, activation functions, models is call() instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='nadam', metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streaming metric(stateful metric):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = keras.metrics.Precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision([0,1,1,1,0,1,0,1], [1,1,0,1,0,1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'true_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>,\n",
       " <tf.Variable 'false_positives:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5714286>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision([0,1,0], [1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'true_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>,\n",
       " <tf.Variable 'false_positives:0' shape=(1,) dtype=float32, numpy=array([3.], dtype=float32)>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'true_positives:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n",
       " <tf.Variable 'false_negatives:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.metrics.Recall().variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customized HuberMetrics subclass Metrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(keras.metrics.Metric):\n",
    "    def __init__(self, delta=1.0, **kwargs):\n",
    "        super(HuberMetric, self).__init__(**kwargs)\n",
    "        self.delta = delta\n",
    "        self.huber_fn = huber_fn(self.delta)\n",
    "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
    "        self.conut = self.add_weight(\"count\", initializer=\"zeros\")\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "    def get_config(self):\n",
    "        base_config = super(HuberMetric, self).get_config()\n",
    "        return {**base_config, \"delta\": self.delta}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers without parameters\n",
    "# use keras.layers.Lambda to wrap\n",
    "# e.g.\n",
    "exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.random.uniform((3,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=float32, numpy=\n",
       "array([[0.9039606 , 0.22642279, 0.31175542, 0.78124166, 0.49105382],\n",
       "       [0.6626599 , 0.30204666, 0.36431026, 0.33980227, 0.7871053 ],\n",
       "       [0.4914937 , 0.27795398, 0.5386164 , 0.27939844, 0.84706664]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=float32, numpy=\n",
       "array([[2.469364 , 1.2541058, 1.3658206, 2.1841826, 1.6340373],\n",
       "       [1.9399455, 1.3526244, 1.439521 , 1.4046699, 2.1970274],\n",
       "       [1.6347562, 1.3204254, 1.7136343, 1.322334 , 2.332794 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponential_layer(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super(MyDense, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name='kernel',\n",
    "            shape=[batch_input_shape[-1], self.units],\n",
    "            initializer=\"glorot_normal\"\n",
    "        )\n",
    "        self.bias = self.add_weight(\n",
    "            name='bias',\n",
    "            shape=[self.units],\n",
    "            initializer='zeros'\n",
    "        )\n",
    "        super(MyDense, self).build(batch_input_shape) # must be at the end\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.weights + self.bias)\n",
    "    def compute_output_shape(self, batch_input_shape): # return tf.TensorShape\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
    "    def get_config(self):\n",
    "        base_config = super(MyDense, self).get_config()\n",
    "        return {**base_config, \"units\": self.units, \"activation\": keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different behavor during training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super(MyGaussianNoise, self).__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "    def call(self, X, training=None):\n",
    "        # add Gaussian noise during training\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super(ResidualBlock, self).__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(n_neurons, activation='relu', \n",
    "                                          kernel_initializer='he_normal') \n",
    "                       for _ in range(n_layers)]\n",
    "        def call(self, X):\n",
    "            Z = X\n",
    "            for layer in self.hidden:\n",
    "                Z = layer(Z)\n",
    "            return Z + X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualRegressor(keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super(ResidualRegressor, self).__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(30, activation='elu', kernel_initialier='he_normal')\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(3 + 1):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses and Metrics Based on Model Internals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom model with a custom reconstruction loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconstructingRegressor(keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super(ReconstructingRegressor, self).__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(30, activation='selu', \n",
    "                                          kernel_initializer='lecun_normal') \n",
    "                       for _ in range(5)]\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "    def build(self, batch_input_shape):\n",
    "        n_inputs = batch_input_shape[-1]\n",
    "        self.reconstruct = keras.layers.Dense(n_inputs)\n",
    "        super(ReconstructingRegressor, self).build(batch_input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        self.add_loss(0.05 * recon_loss)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Gradients Using Autodiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function to illustrate autodiff\n",
    "def f(w1, w2):\n",
    "    return 3 * w1**2 + 2 * w1*w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1, w2 = tf.Variable(5.0), tf.Variable(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "gradient = tape.gradient(z, [w1, w2])\n",
    "gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep tape persisitent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = f(w1, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tape.gradient(z, [w1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tape will only watch the variabels, but we can force it to watch any tensors as we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1, c2 = tf.constant(5.), tf.constant(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tape.gradient(z, [c1, c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(c1)\n",
    "    tape.watch(c2)\n",
    "    z = f(c1, c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tape.gradient(z, [c1 ,c2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop gradient is specific part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1**2 + tf.stop_gradient(2 * w1 * w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=30.0>, None]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some numerical problem in autodiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(100.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=nan>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tape.gradient(z, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use custom_gradient to solve the problem\n",
    "@tf.custom_gradient\n",
    "def my_better_softplus(z):\n",
    "    exp = tf.exp(z)\n",
    "    def my_softplus_gradient(grad):\n",
    "        \"\"\"grad from previous backpropogate gradients\n",
    "        \"\"\"\n",
    "        return grad / (1 + 1/exp)\n",
    "    return tf.math.log(exp + 1), my_softplus_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z = my_better_softplus(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tape.gradient(z, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Training Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = keras.regularizers.l2(0.05)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2_reg),\n",
    "    keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_barch(X, y, batch_size=32):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None):\n",
    "    metrics = \" - \".join([f'{m.name}: {m.result():.4f}' for m in [loss]+(metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(f\"\\r{iteration}/{total} - \" + metrics, end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.Nadam(lr=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.MeanAbsoluteError()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11610/11610 - mean: 1.3744 - mean_absolute_error: 0.9170\n",
      "Epoch 2/5\n",
      "11610/11610 - mean: 1.3467 - mean_absolute_error: 0.9002\n",
      "Epoch 3/5\n",
      "11610/11610 - mean: 1.3756 - mean_absolute_error: 0.9131\n",
      "Epoch 4/5\n",
      "11610/11610 - mean: 1.3368 - mean_absolute_error: 0.9015\n",
      "Epoch 5/5\n",
      "11610/11610 - mean: 1.3675 - mean_absolute_error: 0.9094\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epoch+1):\n",
    "    print(f\"Epoch {epoch}/{n_epoch}\")\n",
    "    for step in range(1, n_steps+1):\n",
    "        X_batch, y_batch = random_barch(X_train, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            # predict\n",
    "            y_pred = model(X_batch, training=True)\n",
    "            \n",
    "            # losses\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred)) # model MSE loss\n",
    "            all_loss_list = [main_loss] + model.losses # MSE loss + layer1 l2 loss + layer2 l2 loss\n",
    "            loss = tf.add_n(all_loss_list) # sum up all losses\n",
    "            \n",
    "        # calcualte and update gradients\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        # calculate metrics\n",
    "        mean_loss(loss) # mean loss(MSE+l2_1+l2_2) average batch\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "        print_status_bar(step*batch_size, len(y_train), mean_loss, metrics)\n",
    "    # print out the total mean_loss\n",
    "    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
    "    # finish epoch, reset all metrics\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code snipet for weights&bias constraint\n",
    "for variable in model.variables:\n",
    "    if variable.constraint is not None:\n",
    "        variable.assign(variable.constraint(variable))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Functions and Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube(x):\n",
    "    return x**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(tf.constant(2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tf.function() to convert this Python function to a TensorFlow Function\n",
    "tf_cube = tf.function(cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(tf.constant(2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or we can use decorator\n",
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    return x**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube.python_function(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoGraph and Tracing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF Function Rules"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
